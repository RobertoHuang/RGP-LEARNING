# 05-2.部署kube-apiserver集群

本文档讲解部署一个三实例`kube-apiserver`集群的步骤.

注意:如果没有特殊指明，本文档的所有操作**均在roberto-k8s-01节点上执行**

## 创建kubernetes-master证书和私钥

- 创建证书签名请求

    ```shell
    cd /opt/k8s/work
    source /opt/k8s/bin/environment.sh
    cat > kubernetes-csr.json <<EOF
    {
      "CN": "kubernetes-master",
      "hosts": [
        "127.0.0.1",
        "10.4.7.11",
        "10.4.7.12",
        "10.4.7.13",
        "${CLUSTER_KUBERNETES_SVC_IP}",
        "kubernetes",
        "kubernetes.default",
        "kubernetes.default.svc",
        "kubernetes.default.svc.cluster",
        "kubernetes.default.svc.cluster.local.",
        "kubernetes.default.svc.${CLUSTER_DNS_DOMAIN}."
      ],
      "key": {
        "algo": "rsa",
        "size": 2048
      },
      "names": [
        {
          "C": "CN",
          "ST": "BeiJing",
          "L": "BeiJing",
          "O": "k8s",
          "OU": "system"
        }
      ]
    }
    EOF
    ```

    `hosts`字段指定授权使用该证书的**IP和域名列表**，这里列出了`master`节点`IP`、`kubernetes`服务的`IP`和域名

- 生成证书和秘钥

    ```shell
    cd /opt/k8s/work
    cfssl gencert -ca=/opt/k8s/work/ca.pem \
      -ca-key=/opt/k8s/work/ca-key.pem \
      -config=/opt/k8s/work/ca-config.json \
      -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes
    ```

- 将生成的证书和私钥文件拷贝到所有`master`节点

    ```
    cd /opt/k8s/work
    source /opt/k8s/bin/environment.sh
    for node_ip in ${NODE_IPS[@]}
      do
        echo ">>> ${node_ip}"
        ssh root@${node_ip} "mkdir -p /etc/kubernetes/cert"
        scp kubernetes*.pem root@${node_ip}:/etc/kubernetes/cert/
      done
    ```

## 创建加密配置文件

```shell
cd /opt/k8s/work
source /opt/k8s/bin/environment.sh
cat > encryption-config.yaml <<EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: ${ENCRYPTION_KEY}
      - identity: {}
EOF
```

将加密配置文件拷贝到`master`节点的`/etc/kubernetes`目录下

```shell
cd /opt/k8s/work
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp encryption-config.yaml root@${node_ip}:/etc/kubernetes/
  done
```

该配置似乎在`1.18.x`已经不生效了，现在还是初学者先抄吧。后续再回过头来看

## 创建审计策略文件

```shell
cd /opt/k8s/work
source /opt/k8s/bin/environment.sh
cat > audit-policy.yaml <<EOF
apiVersion: audit.k8s.io/v1beta1
kind: Policy
rules:
  # The following requests were manually identified as high-volume and low-risk, so drop them.
  - level: None
    resources:
      - group: ""
        resources:
          - endpoints
          - services
          - services/status
    users:
      - 'system:kube-proxy'
    verbs:
      - watch

  - level: None
    resources:
      - group: ""
        resources:
          - nodes
          - nodes/status
    userGroups:
      - 'system:nodes'
    verbs:
      - get

  - level: None
    namespaces:
      - kube-system
    resources:
      - group: ""
        resources:
          - endpoints
    users:
      - 'system:kube-controller-manager'
      - 'system:kube-scheduler'
      - 'system:serviceaccount:kube-system:endpoint-controller'
    verbs:
      - get
      - update

  - level: None
    resources:
      - group: ""
        resources:
          - namespaces
          - namespaces/status
          - namespaces/finalize
    users:
      - 'system:apiserver'
    verbs:
      - get

  # Don't log HPA fetching metrics.
  - level: None
    resources:
      - group: metrics.k8s.io
    users:
      - 'system:kube-controller-manager'
    verbs:
      - get
      - list

  # Don't log these read-only URLs.
  - level: None
    nonResourceURLs:
      - '/healthz*'
      - /version
      - '/swagger*'

  # Don't log events requests.
  - level: None
    resources:
      - group: ""
        resources:
          - events

  # node and pod status calls from nodes are high-volume and can be large, don't log responses
  # for expected updates from nodes
  - level: Request
    omitStages:
      - RequestReceived
    resources:
      - group: ""
        resources:
          - nodes/status
          - pods/status
    users:
      - kubelet
      - 'system:node-problem-detector'
      - 'system:serviceaccount:kube-system:node-problem-detector'
    verbs:
      - update
      - patch

  - level: Request
    omitStages:
      - RequestReceived
    resources:
      - group: ""
        resources:
          - nodes/status
          - pods/status
    userGroups:
      - 'system:nodes'
    verbs:
      - update
      - patch

  # deletecollection calls can be large, don't log responses for expected namespace deletions
  - level: Request
    omitStages:
      - RequestReceived
    users:
      - 'system:serviceaccount:kube-system:namespace-controller'
    verbs:
      - deletecollection

  # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data,
  # so only log at the Metadata level.
  - level: Metadata
    omitStages:
      - RequestReceived
    resources:
      - group: ""
        resources:
          - secrets
          - configmaps
      - group: authentication.k8s.io
        resources:
          - tokenreviews
  # Get repsonses can be large; skip them.
  - level: Request
    omitStages:
      - RequestReceived
    resources:
      - group: ""
      - group: admissionregistration.k8s.io
      - group: apiextensions.k8s.io
      - group: apiregistration.k8s.io
      - group: apps
      - group: authentication.k8s.io
      - group: authorization.k8s.io
      - group: autoscaling
      - group: batch
      - group: certificates.k8s.io
      - group: extensions
      - group: metrics.k8s.io
      - group: networking.k8s.io
      - group: policy
      - group: rbac.authorization.k8s.io
      - group: scheduling.k8s.io
      - group: settings.k8s.io
      - group: storage.k8s.io
    verbs:
      - get
      - list
      - watch

  # Default level for known APIs
  - level: RequestResponse
    omitStages:
      - RequestReceived
    resources:
      - group: ""
      - group: admissionregistration.k8s.io
      - group: apiextensions.k8s.io
      - group: apiregistration.k8s.io
      - group: apps
      - group: authentication.k8s.io
      - group: authorization.k8s.io
      - group: autoscaling
      - group: batch
      - group: certificates.k8s.io
      - group: extensions
      - group: metrics.k8s.io
      - group: networking.k8s.io
      - group: policy
      - group: rbac.authorization.k8s.io
      - group: scheduling.k8s.io
      - group: settings.k8s.io
      - group: storage.k8s.io
      
  # Default level for all other requests.
  - level: Metadata
    omitStages:
      - RequestReceived
EOF
```

分发审计策略文件

```shell
cd /opt/k8s/work
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp audit-policy.yaml root@${node_ip}:/etc/kubernetes/audit-policy.yaml
  done
```

## 创建后续访问metrics-server或kube-prometheus使用的证书

- 创建证书请求

    ```shell
    cd /opt/k8s/work
    cat > proxy-client-csr.json <<EOF
    {
      "CN": "aggregator",
      "hosts": [],
      "key": {
        "algo": "rsa",
        "size": 2048
      },
      "names": [
        {
          "C": "CN",
          "ST": "BeiJing",
          "L": "BeiJing",
          "O": "k8s",
          "OU": "system"
        }
      ]
    }
    EOF
    ```

    `CN`名称需要位于`kube-apiserver`的`--requestheader-allowed-names`参数中，否则后续访问`metrics`时会提示权限不足

- 生成证书和私钥

    ```shell
    cfssl gencert -ca=/etc/kubernetes/cert/ca.pem \
      -ca-key=/etc/kubernetes/cert/ca-key.pem  \
      -config=/etc/kubernetes/cert/ca-config.json  \
      -profile=kubernetes proxy-client-csr.json | cfssljson -bare proxy-client
    ```

- 将生成的证书和私钥文件拷贝到所有`master`节点

    ```
    cd /opt/k8s/work
    source /opt/k8s/bin/environment.sh
    for node_ip in ${NODE_IPS[@]}
      do
        echo ">>> ${node_ip}"
        scp proxy-client*.pem root@${node_ip}:/etc/kubernetes/cert/
      done
    ```

## 创建kube-apiserver systemd unit文件

- 创建`kube-apiserver systemd unit`模板文件

    ```shell
    cd /opt/k8s/work
    source /opt/k8s/bin/environment.sh
    cat > kube-apiserver.service.template <<EOF
    [Unit]
    Description=Kubernetes API Server
    Documentation=https://github.com/GoogleCloudPlatform/kubernetes
    After=network.target
    
    [Service]
    WorkingDirectory=${K8S_DIR}/kube-apiserver
    ExecStart=/opt/k8s/bin/kube-apiserver \\
        --advertise-address=##NODE_IP## \\
        --default-not-ready-toleration-seconds=360 \\
        --default-unreachable-toleration-seconds=360 \\
        --feature-gates=DynamicAuditing=true \\
        --max-mutating-requests-inflight=2000 \\
        --max-requests-inflight=4000 \\
        --default-watch-cache-size=200 \\
        --delete-collection-workers=2 \\
        --encryption-provider-config=/etc/kubernetes/encryption-config.yaml \\
        --etcd-cafile=/etc/kubernetes/cert/ca.pem \\
        --etcd-certfile=/etc/kubernetes/cert/kubernetes.pem \\
        --etcd-keyfile=/etc/kubernetes/cert/kubernetes-key.pem \\
        --etcd-servers=${ETCD_ENDPOINTS} \\
        --bind-address=##NODE_IP## \\
        --secure-port=6443 \\
        --tls-cert-file=/etc/kubernetes/cert/kubernetes.pem \\
        --tls-private-key-file=/etc/kubernetes/cert/kubernetes-key.pem \\
        --insecure-port=0 \\
        --audit-dynamic-configuration \\
        --audit-log-maxage=15 \\
        --audit-log-maxbackup=3 \\
        --audit-log-maxsize=100 \\
        --audit-log-truncate-enabled \\
        --audit-log-path=${K8S_DIR}/kube-apiserver/audit.log \\
        --audit-policy-file=/etc/kubernetes/audit-policy.yaml \\
        --profiling \\
        --anonymous-auth=false \\
        --client-ca-file=/etc/kubernetes/cert/ca.pem \\
        --enable-bootstrap-token-auth \\
        --requestheader-allowed-names="aggregator" \\
        --requestheader-client-ca-file=/etc/kubernetes/cert/ca.pem \\
        --requestheader-extra-headers-prefix="X-Remote-Extra-" \\
        --requestheader-group-headers=X-Remote-Group \\
        --requestheader-username-headers=X-Remote-User \\
        --service-account-key-file=/etc/kubernetes/cert/ca.pem \\
        --authorization-mode=Node,RBAC \\
        --runtime-config=api/all=true \\
        --enable-admission-plugins=NodeRestriction \\
        --allow-privileged=true \\
        --apiserver-count=3 \\
        --event-ttl=168h \\
        --kubelet-certificate-authority=/etc/kubernetes/cert/ca.pem \\
        --kubelet-client-certificate=/etc/kubernetes/cert/kubernetes.pem \\
        --kubelet-client-key=/etc/kubernetes/cert/kubernetes-key.pem \\
        --kubelet-https=true \\
        --kubelet-timeout=10s \\
        --proxy-client-cert-file=/etc/kubernetes/cert/proxy-client.pem \\
        --proxy-client-key-file=/etc/kubernetes/cert/proxy-client-key.pem \\
        --service-cluster-ip-range=${SERVICE_CIDR} \\
        --service-node-port-range=${NODE_PORT_RANGE} \\
        --logtostderr=true \\
        --v=2
    Restart=on-failure
    RestartSec=10
    Type=notify
    LimitNOFILE=65536
    
    [Install]
    WantedBy=multi-user.target
    EOF
    ```

    上述所有配置项均可参考[api-server配置文档](https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/)，作为`kubernetes`新手我只是照搬了别人写好的配置。可能部分配置也已经过时

- 为各节点创建和分发`kube-controller-mananger systemd unit`文件
    - 替换模板文件中的变量，为各节点创建`systemd unit`文件

        ```shell
        cd /opt/k8s/work
        source /opt/k8s/bin/environment.sh
        for (( i=0; i < 3; i++ ))
          do
            sed -e "s/##NODE_NAME##/${NODE_NAMES[i]}/" -e "s/##NODE_IP##/${NODE_IPS[i]}/" kube-apiserver.service.template > kube-apiserver-${NODE_IPS[i]}.service 
          done
        ls kube-apiserver*.service
        ```

    - 为各节点分发生成的`systemd unit`文件

        ```shell
        cd /opt/k8s/work
        source /opt/k8s/bin/environment.sh
        for node_ip in ${NODE_IPS[@]}
          do
            echo ">>> ${node_ip}"
            scp kube-apiserver-${node_ip}.service root@${node_ip}:/etc/systemd/system/kube-apiserver.service
          done
        ```

## 启动kube-apiserver服务

```shell
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    ssh root@${node_ip} "mkdir -p ${K8S_DIR}/kube-apiserver"
    ssh root@${node_ip} "systemctl daemon-reload && systemctl enable kube-apiserver && systemctl restart kube-apiserver"
  done
```

## 检查kube-apiserver运行状态

```shell
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    ssh root@${node_ip} "systemctl status kube-apiserver |grep 'Active:'"
  done
```

确保状态为`active (running)`，否则查看日志确认原因

```
journalctl -u kube-apiserver
```

## 检查集群状态

```
# kubectl cluster-info
Kubernetes master is running at https://10.4.7.11:6443

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

# kubectl get all --all-namespaces
NAMESPACE   NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
default     service/kubernetes   ClusterIP   10.254.0.1   <none>        443/TCP   2m3s

# kubectl get componentstatuses
NAME                 STATUS      MESSAGE                                                                                     ERROR
scheduler            Unhealthy   Get http://127.0.0.1:10251/healthz: dial tcp 127.0.0.1:10251: connect: connection refused
controller-manager   Unhealthy   Get http://127.0.0.1:10252/healthz: dial tcp 127.0.0.1:10252: connect: connection refused
etcd-2               Healthy     {"health":"true"}
etcd-0               Healthy     {"health":"true"}
etcd-1               Healthy     {"health":"true"}
```

## 检查kube-apiserver监听的端口

```
# netstat -lnpt|grep kube
tcp        0      0 10.4.7.11:6443          0.0.0.0:*               LISTEN      6332/kube-apiserver
```

`api-server`监听6443端口接收`https`请求，对所有请求做认证和授权。由于关闭了非安全端口故没有监听8080